# üìä EJEMPLOS DE USO DEL CSV EXPORTADO

## Casos de Uso Pr√°cticos

---

## 1. üìà An√°lisis en Excel

### Abrir el archivo
1. Abrir Excel
2. Archivo ‚Üí Abrir
3. Seleccionar el CSV descargado
4. Excel lo importa autom√°ticamente

### Crear tabla din√°mica
1. Seleccionar todos los datos
2. Insertar ‚Üí Tabla din√°mica
3. Arrastrar "Tipo Alerta" a Filas
4. Arrastrar "ID Reporte" a Valores (contar)
5. Ver distribuci√≥n de alertas por tipo

### Gr√°fico de barras
1. Seleccionar columna "Tipo Alerta"
2. Insertar ‚Üí Gr√°fico de barras
3. Visualizar qu√© tipo de alerta es m√°s com√∫n

### Filtros
1. Seleccionar encabezados
2. Datos ‚Üí Filtro
3. Filtrar por fecha, animal, tipo, etc.

---

## 2. üêç An√°lisis en Python (pandas)

### Cargar CSV
```python
import pandas as pd
import matplotlib.pyplot as plt

# Cargar datos
df = pd.read_csv('reportes_camport_20250119.csv')

# Ver primeras filas
print(df.head())
```

### Estad√≠sticas b√°sicas
```python
# Contar alertas por tipo
print(df['Tipo Alerta'].value_counts())

# Estad√≠sticas de valores registrados
print(df['Valor Registrado'].describe())

# Alertas por animal
print(df.groupby('Collar ID').size())
```

### An√°lisis de temperatura
```python
# Filtrar solo alertas de temperatura
temp = df[df['Tipo Alerta'] == 'TEMPERATURA']

# Convertir valores a num√©rico
temp['Valor'] = pd.to_numeric(temp['Valor Registrado'], errors='coerce')

# Estad√≠sticas
print(f"Temperatura promedio: {temp['Valor'].mean():.2f}¬∞C")
print(f"Temperatura m√°xima: {temp['Valor'].max():.2f}¬∞C")
print(f"Temperatura m√≠nima: {temp['Valor'].min():.2f}¬∞C")
```

### Gr√°ficos
```python
# Gr√°fico de barras: alertas por tipo
df['Tipo Alerta'].value_counts().plot(kind='bar')
plt.title('Distribuci√≥n de Alertas por Tipo')
plt.xlabel('Tipo de Alerta')
plt.ylabel('Cantidad')
plt.show()

# Gr√°fico de pastel: alertas por animal
df['Collar ID'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Alertas por Animal')
plt.show()
```

### An√°lisis temporal
```python
# Convertir fechas
df['Fecha Alerta'] = pd.to_datetime(df['Fecha Alerta'])

# Agrupar por d√≠a
por_dia = df.groupby(df['Fecha Alerta'].dt.date).size()
por_dia.plot(kind='line')
plt.title('Alertas por D√≠a')
plt.xlabel('Fecha')
plt.ylabel('Cantidad de Alertas')
plt.xticks(rotation=45)
plt.show()
```

---

## 3. üìä An√°lisis en R

```r
# Cargar datos
library(tidyverse)

df <- read_csv("reportes_camport_20250119.csv")

# Ver estructura
glimpse(df)

# Contar por tipo
df %>% 
  group_by(`Tipo Alerta`) %>% 
  summarise(n = n()) %>%
  arrange(desc(n))

# Gr√°fico
ggplot(df, aes(x = `Tipo Alerta`)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Alertas por Tipo",
       x = "Tipo de Alerta",
       y = "Cantidad") +
  theme_minimal()
```

---

## 4. üìà Power BI

### Importar datos
1. Abrir Power BI Desktop
2. Obtener datos ‚Üí Texto/CSV
3. Seleccionar archivo CSV
4. Click en "Cargar"

### Crear visualizaciones
1. **Tarjeta**: Total de reportes
2. **Gr√°fico de barras**: Alertas por tipo
3. **Gr√°fico circular**: Distribuci√≥n por animal
4. **Tabla**: Detalles de alertas
5. **L√≠nea temporal**: Alertas por fecha

### Medidas DAX
```dax
Total Alertas = COUNT(Reportes[ID Reporte])

Temperatura Promedio = 
CALCULATE(
    AVERAGE(Reportes[Valor Registrado]),
    Reportes[Tipo Alerta] = "TEMPERATURA"
)

Alertas Cr√≠ticas = 
CALCULATE(
    COUNT(Reportes[ID Reporte]),
    OR(
        Reportes[Tipo Alerta] = "PERIMETRO",
        AND(
            Reportes[Tipo Alerta] = "TEMPERATURA",
            Reportes[Valor Registrado] > 40
        )
    )
)
```

---

## 5. üîç Google Sheets

### Importar CSV
1. Abrir Google Sheets
2. Archivo ‚Üí Importar
3. Subir ‚Üí Seleccionar CSV
4. Click en "Importar datos"

### F√≥rmulas √∫tiles
```
// Contar alertas de temperatura
=COUNTIF(E:E, "TEMPERATURA")

// Temperatura promedio
=AVERAGEIF(E:E, "TEMPERATURA", G:G)

// Alertas por animal
=UNIQUE(B:B)
=COUNTIF(B:B, "EQUINO-001")

// Filtrar por fecha
=FILTER(A:M, H:H >= DATE(2025,1,1))
```

### Tabla din√°mica
1. Datos ‚Üí Tabla din√°mica
2. Filas: Tipo Alerta
3. Valores: CUENTA de ID Reporte
4. Columnas: Collar ID

---

## 6. üìß Env√≠o por Email Automatizado

### Python
```python
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders

def enviar_reporte(csv_path, destinatario):
    msg = MIMEMultipart()
    msg['Subject'] = 'Reporte de Alertas - CAMPORT'
    msg['From'] = 'sistema@camport.com'
    msg['To'] = destinatario
    
    # Adjuntar CSV
    with open(csv_path, 'rb') as f:
        part = MIMEBase('application', 'octet-stream')
        part.set_payload(f.read())
        encoders.encode_base64(part)
        part.add_header('Content-Disposition', 
                       f'attachment; filename={os.path.basename(csv_path)}')
        msg.attach(part)
    
    # Enviar
    smtp = smtplib.SMTP('smtp.gmail.com', 587)
    smtp.starttls()
    smtp.login('usuario@gmail.com', 'password')
    smtp.send_message(msg)
    smtp.quit()
```

---

## 7. üóÑÔ∏è Importar a Base de Datos

### MySQL
```sql
LOAD DATA LOCAL INFILE 'reportes_camport_20250119.csv'
INTO TABLE reportes
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS
(id_reporte, collar_id, display_id, tipo_animal, tipo_alerta, 
 mensaje, valor_registrado, @fecha_alerta, @fecha_resolucion, 
 @fecha_generacion, generado_por, observaciones, exportado)
SET fecha_alerta = STR_TO_DATE(@fecha_alerta, '%Y-%m-%d %H:%i:%s'),
    fecha_resolucion = STR_TO_DATE(@fecha_resolucion, '%Y-%m-%d %H:%i:%s'),
    fecha_generacion = STR_TO_DATE(@fecha_generacion, '%Y-%m-%d %H:%i:%s');
```

### PostgreSQL
```sql
COPY reportes (
    id_reporte, collar_id, display_id, tipo_animal, tipo_alerta,
    mensaje, valor_registrado, fecha_alerta, fecha_resolucion,
    fecha_generacion, generado_por, observaciones, exportado
)
FROM '/path/to/reportes_camport_20250119.csv'
DELIMITER ','
CSV HEADER;
```

---

## 8. üîÑ Integraci√≥n con Sistemas Externos

### API REST
```python
import requests
import csv

# Leer CSV
with open('reportes_camport_20250119.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        # Enviar cada reporte a API externa
        response = requests.post('https://api.externa.com/alertas', json={
            'animal_id': row['Collar ID'],
            'tipo': row['Tipo Alerta'],
            'valor': row['Valor Registrado'],
            'fecha': row['Fecha Alerta']
        })
        print(f"Enviado: {row['ID Reporte']} - Status: {response.status_code}")
```

---

## 9. üì± Dashboard en Tiempo Real

### Streamlit (Python)
```python
import streamlit as st
import pandas as pd
import plotly.express as px

st.title('üìä Dashboard de Alertas CAMPORT')

# Cargar datos
df = pd.read_csv('reportes_camport_20250119.csv')

# KPIs
col1, col2, col3 = st.columns(3)
col1.metric("Total Alertas", len(df))
col2.metric("Animales Afectados", df['Collar ID'].nunique())
col3.metric("Promedio Temp", f"{df[df['Tipo Alerta']=='TEMPERATURA']['Valor Registrado'].mean():.1f}¬∞C")

# Gr√°ficos
st.plotly_chart(
    px.bar(df['Tipo Alerta'].value_counts().reset_index(), 
           x='index', y='Tipo Alerta', 
           title='Distribuci√≥n de Alertas')
)

# Tabla
st.dataframe(df)
```

---

## 10. ü§ñ Machine Learning

### Predicci√≥n de alertas
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Preparar datos
df['Fecha'] = pd.to_datetime(df['Fecha Alerta'])
df['hora'] = df['Fecha'].dt.hour
df['dia_semana'] = df['Fecha'].dt.dayofweek

# Features
X = df[['hora', 'dia_semana']]
y = df['Tipo Alerta']

# Entrenar
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Predecir
accuracy = model.score(X_test, y_test)
print(f"Precisi√≥n: {accuracy:.2%}")
```

---

## üí° TIPS ADICIONALES

### Automatizaci√≥n
- Crear script para descargar CSV autom√°ticamente cada d√≠a
- Usar cron (Linux) o Task Scheduler (Windows)
- Enviar reporte por email autom√°ticamente

### Visualizaci√≥n
- Crear dashboard en Tableau
- Usar Google Data Studio
- Implementar Grafana

### An√°lisis Avanzado
- Detecci√≥n de anomal√≠as
- Clustering de animales por comportamiento
- Predicci√≥n de fugas

---

**Fecha**: 2025-01-19
**Versi√≥n**: 1.0.0
**Autor**: GitHub Copilot
